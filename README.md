# 3D Breast Cancer Segmentation using MRI and nnU-Net

This repository presents a complete deep learning pipeline for **3D breast cancer segmentation** using volumetric MRI data and the **nnU-Net architecture**. It leverages the BreastDM dataset to identify tumor regions with high spatial precision in the subtraction (SUB2) modality.

---

## Project Structure

```bash
.
â”œâ”€â”€ 1_dataprep_&_preprocessing.ipynb              # Data loading, normalization, padding
â”œâ”€â”€ 2_training.ipynb                              # 3D nnU-Net model training (PyTorch)
â”œâ”€â”€ 3_inference.ipynb                             # Inference on test samples
â”œâ”€â”€ 4_postprocessing_visualization_evaluation.ipynb  # Postprocessing, visualization, evaluation
â”œâ”€â”€ sample_output/                                # (Optional) Small sample predictions for quick testing
â””â”€â”€ README.md

```

## ðŸ“‚ Data & Results Access

All large data used and generated by the pipeline is hosted on Google Drive:

ðŸ”— [**Google Drive Folder â€“ Breast Cancer Segmentation Data & Outputs**](https://drive.google.com/drive/folders/1qsWCs7Kgdx3kHS0HAzy1GjV-gVhqODOI?usp=sharing)

Contents include:
- `preprocessed_data/`: Preprocessed `.npy` volumes used for model input
- `results/`: Predicted 3D masks and overlays
- `nnUNet_trained_models/`: Trained model weights, logs, and configuration
- `predictions/`: Inference outputs for test data
- `evaluation/`: Dice score, IoU, sensitivity, and other metrics
- `progress_plots/`: Training/validation curves
- `fingerprints.json`: nnU-Net config fingerprints for reproducibility

> ðŸ” The folder is shared in read-only mode for reproducibility and model re-use.

---

## Dataset: BreastDM

- **Patients**: 262
- **Modalities** per patient:
  - `SUB2.npy`
  - `VIBRANT.npy`,
  - `VIBRANT+C2.npy`
- **Format**: 3D `.npy` volumes of shape `(H, W, D)`
- **Mask**: Binary ground truth masks for tumor regions
- **Data Splits**: `train/`, `val/`, and `test/` (each with `images/` and `labels/` subfolders)

> Input tensors are padded and reshaped to fixed shapes like `(8, 3, 369, 369)` or `(6, 3, 369, 369)`.

---

## Model Overview: nnU-Net (3D)

The model is a 3D implementation of the popular nnU-Net framework. Key features:

- Fully convolutional 3D segmentation architecture
- Automatic adaptation to patch sizes and resolution
- Works directly on 3D MRI volumes (`SUB2.npy`)
- Postprocessing pipeline to enhance segmentation quality

---

## Pipeline Steps

### 1. Data Preprocessing  
 `1_dataprep_&_preprocessing.ipynb`

- Loads `SUB2.npy` volumes and their corresponding labels
- Normalizes intensities
- Pads volumes to consistent shape
- Saves preprocessed volumes to disk for model input

---

### 2. Model Training  
 `2_training.ipynb`

- Implements 3D nnU-Net using PyTorch
- Trains model on preprocessed data
- Logs metrics and saves checkpoints to Drive

---

### 3. Inference  
 `3_inference.ipynb`

- Loads trained model
- Predicts tumor masks on test samples
- Saves predictions to disk

---

### 4. Postprocessing & Evaluation  
 `4_postprocessing_visualization_evaluation.ipynb`

- Applies connected component filtering to clean predictions
- Computes:
  - Dice Score
  - Intersection over Union (IoU)
  - Sensitivity
  - Specificity
- Visualizes:
  - Ground truth vs predicted masks
  - Overlay on original slices

---

## Results (Sample)

| Metric  | Value |
|------   |-------|
| DSC %   |  86.9 |
| IoU %   |  80.5 |
| PPV %   |  87.6 |


---

## Requirements

- Python 3.9+
- PyTorch 1.12+
- NumPy
- Matplotlib
- Scikit-learn
- nibabel *(if working with NIfTI files)*
- Jupyter Notebook

Install dependencies using:

```bash
pip install -r requirements.txt
```

```bash
from google.colab import drive
drive.mount('/content/drive')

# Then access data like:
!ls /content/drive/MyDrive/path_to_your_data
```
